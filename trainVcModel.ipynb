{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample corpus (replace with your own text data)\n",
    "corpus = [\n",
    "    \"I enjoy natural language processing.\",\n",
    "    \"Word embeddings are useful for NLP tasks.\",\n",
    "    \"Gensim is a popular library for Word2Vec.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"Word2Vec can capture semantic relationships.\",\n",
    "]\n",
    "\n",
    "# Tokenize the corpus (convert sentences into lists of words)\n",
    "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"word2vec_model.model\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = Word2Vec.load(\"word2vec_model.model\")\n",
    "\n",
    "# Find the vector representation of a word\n",
    "word_vector = loaded_model.wv['natural']\n",
    "loaded_model.wv.similarity(\"is\",\"embeddings\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
